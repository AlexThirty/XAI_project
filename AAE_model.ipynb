{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "umSXcy14t3Hj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from datetime import datetime as dt\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "random_seed = 42\n",
        "tf.random.set_seed(random_seed)\n",
        "np.random.seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nPJvpqY_t3Hl"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "def preprocess_images(images):\n",
        "    images = images.reshape((images.shape[0], 32, 32, 3)).astype('float32') / 255.\n",
        "    return images\n",
        "\n",
        "train_images = preprocess_images(train_images)\n",
        "test_images = preprocess_images(test_images)\n",
        "\n",
        "length = train_images.shape[1]\n",
        "width = train_images.shape[2]\n",
        "channels = train_images.shape[3]\n",
        "\n",
        "train_size = train_images.shape[0]\n",
        "test_size = test_images.shape[0]\n",
        "batch_size = 128\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(train_size).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(test_images).shuffle(test_size).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U94JGeJ0t3Hn"
      },
      "outputs": [],
      "source": [
        "class Sampling(tf.keras.layers.Layer):\n",
        "    @tf.function\n",
        "    def call(self, inputs, training=False):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LR_SCHEDULE = [\n",
        "    (25, 0.0001),\n",
        "    (50, 0.00005),\n",
        "    (75, 0.00002),\n",
        "    (100, 0.00001),\n",
        "]\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
        "        return lr\n",
        "    for i in range(len(LR_SCHEDULE)):\n",
        "        if epoch == LR_SCHEDULE[i][0]:\n",
        "            return LR_SCHEDULE[i][1]\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomAAECallbacks(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, X, schedule, patience=0):\n",
        "        super(CustomAAECallbacks, self).__init__()\n",
        "        # Immagini per la ricostruzione\n",
        "        self.X = X\n",
        "        self.patience = patience\n",
        "        self.schedule = schedule\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "        self.ae_best = np.Inf\n",
        "        self.gen_best = np.Inf\n",
        "        self.dc_best = np.Inf\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        ae_lr = float(tf.keras.backend.get_value(self.model.ae_optimizer.learning_rate))\n",
        "        gen_lr = float(tf.keras.backend.get_value(self.model.gen_optimizer.learning_rate))\n",
        "        dc_lr = float(tf.keras.backend.get_value(self.model.dc_optimizer.learning_rate))\n",
        "        scheduled_ae_lr = self.schedule(epoch, ae_lr)\n",
        "        scheduled_dc_lr = self.schedule(epoch, dc_lr)\n",
        "        scheduled_gen_lr = self.schedule(epoch, gen_lr)\n",
        "        tf.keras.backend.set_value(self.model.ae_optimizer.lr, scheduled_ae_lr)\n",
        "        tf.keras.backend.set_value(self.model.gen_optimizer.lr, scheduled_gen_lr)\n",
        "        tf.keras.backend.set_value(self.model.dc_optimizer.lr, scheduled_dc_lr)\n",
        "        print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (epoch, scheduled_ae_lr))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Save 10 reconstructions every 10 epochs\n",
        "        if epoch%10==0:\n",
        "            self.model.save_10_reconstructions(self.X, epoch)\n",
        "\n",
        "        current_ae_loss = logs.get(\"val_ae_loss\")\n",
        "        current_gen_loss = logs.get(\"val_gen_loss\")\n",
        "        current_dc_loss = logs.get(\"val_dc_loss\")\n",
        "        if np.less(current_ae_loss, self.ae_best) or np.less(current_gen_loss, self.gen_best) or np.less(current_dc_loss, self.dc_best):\n",
        "            self.ae_best = current_ae_loss\n",
        "            self.dc_best = current_dc_loss\n",
        "            self.gen_best = current_gen_loss\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "        \n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.stopped_epoch > 0:\n",
        "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-ex4yi9It3Ho"
      },
      "outputs": [],
      "source": [
        "def get_encoder(input_shape, latent_dim, leaky_alpha, filters, kernel_size, strides, dense_units):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=filters[0], kernel_size=kernel_size[0], strides=strides[0], padding='same', kernel_regularizer='l2')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.LeakyReLU(leaky_alpha)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=filters[1], kernel_size=kernel_size[1], strides=strides[1], padding='same', kernel_regularizer='l2')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.LeakyReLU(leaky_alpha)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=filters[2], kernel_size=kernel_size[2], strides=strides[2], padding='same', kernel_regularizer='l2')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.LeakyReLU(leaky_alpha)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=filters[3], kernel_size=kernel_size[3], strides=strides[3], padding='same', kernel_regularizer='l2')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.LeakyReLU(leaky_alpha)(x)\n",
        "\n",
        "    flatten = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(dense_units[0], activation='relu', kernel_regularizer='l2')(flatten)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    z_mean = tf.keras.layers.Dense(latent_dim)(x)\n",
        "    z_log_var = tf.keras.layers.Dense(latent_dim)(x)\n",
        "\n",
        "    z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "    model = tf.keras.Model(inputs, z, name=\"Encoder\")\n",
        "    return model\n",
        "\n",
        "def get_decoder(input_shape, latent_dim, leaky_alpha, filters, kernel_size, strides, dense_units, stride_reduction):\n",
        "    inputs = tf.keras.Input(shape=(latent_dim,))\n",
        "\n",
        "    x = tf.keras.layers.Dense(dense_units[0], activation='relu', kernel_regularizer='l2')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dense(int(input_shape[0]*input_shape[1]*filters[3]/stride_reduction**2), activation='relu', kernel_regularizer='l2')(x)\n",
        "    \n",
        "    reshaped = tf.keras.layers.Reshape((int(input_shape[0]/stride_reduction), int(input_shape[1]/stride_reduction), filters[3]))(x)\n",
        "    x = tf.keras.layers.Conv2DTranspose(filters=filters[3], kernel_size=kernel_size[3], strides=strides[3], padding='same', kernel_regularizer='l2')(reshaped)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.LeakyReLU(leaky_alpha)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2DTranspose(filters=filters[2], kernel_size=kernel_size[2], strides=strides[2], padding='same', kernel_regularizer='l2')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.LeakyReLU(leaky_alpha)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2DTranspose(filters=filters[1], kernel_size=kernel_size[1], strides=strides[1], padding='same', kernel_regularizer='l2')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.LeakyReLU(leaky_alpha)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2DTranspose(filters=filters[0], kernel_size=kernel_size[0], strides=strides[0], padding='same', kernel_regularizer='l2')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.LeakyReLU(leaky_alpha)(x)\n",
        "\n",
        "    image = tf.keras.layers.Conv2DTranspose(filters=input_shape[2], kernel_size=kernel_size[0], strides=1, padding='same', kernel_regularizer='l2')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, image, name=\"Decoder\")\n",
        "    return model\n",
        "\n",
        "def get_discriminator(latent_dim, discriminator_units):\n",
        "    inputs = tf.keras.Input(shape=(latent_dim,))\n",
        "\n",
        "    x = tf.keras.layers.Dense(discriminator_units[0], activation='relu', kernel_regularizer='l2')(inputs)\n",
        "    x = tf.keras.layers.Dense(discriminator_units[1], activation='relu', kernel_regularizer='l2')(x)\n",
        "\n",
        "    vote = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, vote, name=\"Discriminator\")\n",
        "    return model\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hc4qrAxSt3Hr"
      },
      "outputs": [],
      "source": [
        "class AAE(tf.keras.Model):\n",
        "    def __init__(self, input_shape, latent_dim, leaky_alpha, filters, kernel_size, strides, dense_units, discriminator_units, base_lr, max_lr, step_size, gen_coef, batch_size):\n",
        "        super(AAE, self).__init__()\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        # Calculate the stride factor of downsampling\n",
        "        self.stride_reduction = 1\n",
        "        for i, stride in enumerate(strides):\n",
        "            self.stride_reduction = self.stride_reduction * stride\n",
        "        \n",
        "        # Latent dimension\n",
        "        self.latent_dim = latent_dim\n",
        "        # Define losses and accuracies\n",
        "        self.mse = tf.keras.losses.MeanSquaredError()\n",
        "        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "        self.dc_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "        # Define the learning rates for cyclic learning rate (not used)\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.gen_coef = gen_coef\n",
        "\n",
        "        # Encoder Net\n",
        "        self.encoder = get_encoder(input_shape, latent_dim, leaky_alpha, filters, kernel_size, strides, dense_units)\n",
        "\n",
        "        # Decoder Net\n",
        "        self.decoder = get_decoder(input_shape, latent_dim, leaky_alpha, filters, kernel_size, strides, dense_units, self.stride_reduction)\n",
        "\n",
        "        # Discriminator Net\n",
        "        self.discriminator = get_discriminator(latent_dim, discriminator_units)\n",
        "\n",
        "    def compile(self, ae_opt, dc_opt, gen_opt):\n",
        "        super(AAE, self).compile()\n",
        "        # Set optimizers\n",
        "        self.ae_optimizer = ae_opt\n",
        "        self.gen_optimizer = gen_opt\n",
        "        self.dc_optimizer = dc_opt\n",
        "        # Set loss functions\n",
        "        self.ae_loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "        self.binCe_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "        # Set metrics and accuracies\n",
        "        self.dc_acc_fn = tf.keras.metrics.BinaryAccuracy(name='dc_accuracy')\n",
        "        self.ae_metrics = tf.keras.metrics.MeanSquaredError(name='ae_loss')\n",
        "        self.dc_metrics = tf.keras.metrics.BinaryCrossentropy(from_logits=True, name='dc_loss')\n",
        "        self.gen_metrics = tf.keras.metrics.BinaryCrossentropy(from_logits=True, name='gen_loss')\n",
        "        # Compile internal models\n",
        "        self.encoder.compile()\n",
        "        self.decoder.compile()\n",
        "        self.discriminator.compile()\n",
        "\n",
        "    # Define the metrics\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.dc_acc_fn, self.ae_metrics, self.dc_metrics, self.gen_metrics]\n",
        "\n",
        "    # Encoding function\n",
        "    def encode(self, x, training=False):\n",
        "        return self.encoder(x, training=training)\n",
        "\n",
        "    # Decoding function\n",
        "    def decode(self, z, apply_sigmoid=False, training=False):\n",
        "        logits = self.decoder(z, training=training)\n",
        "        if apply_sigmoid:\n",
        "            probs = tf.sigmoid(logits)\n",
        "            return probs\n",
        "        return logits\n",
        "    \n",
        "    # Save 10 reconstructions\n",
        "    def save_10_reconstructions(self, X, epoch):\n",
        "        fig, ax = plt.subplots(2,5,figsize=(15,5))\n",
        "        images = X[:10,:,:,:].reshape((10,32,32,3))\n",
        "        z = self.encode(images)\n",
        "        image_reconstruction = self.decode(z, apply_sigmoid=True).numpy()\n",
        "        for i in range(10):\n",
        "            ax.ravel()[i].imshow(image_reconstruction[i,:])\n",
        "            ax.ravel()[i].axis(False)\n",
        "        fig.savefig(f'reconstructed_epoch_{epoch+1:03d}.png',bbox_inches='tight')\n",
        "\n",
        "    @tf.function\n",
        "    def test_step(self, batch_x):\n",
        "        generated_noise = tf.random.normal([self.batch_size, self.latent_dim], mean=0.0, stddev=1.0)\n",
        "        z_generated = self.encode(batch_x)\n",
        "        X_reconstructed = self.decode(z_generated, apply_sigmoid=True)\n",
        "                \n",
        "        dc_fake = self.discriminator(z_generated)\n",
        "        dc_real = self.discriminator(generated_noise)\n",
        "\n",
        "        self.ae_metrics.update_state(batch_x, X_reconstructed)\n",
        "        self.dc_metrics.update_state(tf.concat([tf.zeros_like(dc_fake), tf.ones_like(dc_real)], axis=0), tf.concat([dc_fake, dc_real], axis=0))\n",
        "        self.gen_metrics.update_state(tf.ones_like(dc_fake), dc_fake)\n",
        "        self.dc_acc_fn.update_state(tf.concat([tf.zeros_like(dc_fake), tf.ones_like(dc_real)], axis=0), tf.concat([dc_fake, dc_real], axis=0))\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "\n",
        "    # Function for the train step\n",
        "    @tf.function\n",
        "    def train_step(self, batch_x):\n",
        "        # Autoencoder training\n",
        "        with tf.GradientTape() as ae_tape:\n",
        "            z_generated = self.encode(batch_x, training=True)\n",
        "            X_reconstructed = self.decode(z_generated, apply_sigmoid=True, training=True)\n",
        "            ae_loss = self.ae_loss_fn(batch_x, X_reconstructed)\n",
        "\n",
        "        # Apply the gradients\n",
        "        ae_grads = ae_tape.gradient(ae_loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
        "        self.ae_optimizer.apply_gradients(zip(ae_grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
        "\n",
        "        # Discriminator training with normal prior\n",
        "        generated_noise = tf.random.normal([self.batch_size, self.latent_dim], mean=0.0, stddev=1.0)\n",
        "        with tf.GradientTape() as dc_tape:\n",
        "            encoder_output = self.encode(batch_x, training=False)\n",
        "            dc_fake = self.discriminator(encoder_output, training=True)\n",
        "            dc_real = self.discriminator(generated_noise, training=True)\n",
        "\n",
        "            real_loss = self.binCe_loss_fn(tf.ones_like(dc_real), dc_real)\n",
        "            fake_loss = self.binCe_loss_fn(tf.zeros_like(dc_fake), dc_fake)\n",
        "            dc_loss = real_loss + fake_loss\n",
        "\n",
        "            dc_acc = self.dc_acc_fn(tf.concat([tf.ones_like(dc_real), tf.zeros_like(dc_fake)], axis=0),\n",
        "                        tf.concat([dc_real, dc_fake], axis=0))\n",
        "\n",
        "        # Apply the gradients\n",
        "        dc_grads = dc_tape.gradient(dc_loss, self.discriminator.trainable_variables)\n",
        "        self.dc_optimizer.apply_gradients(zip(dc_grads, self.discriminator.trainable_variables))\n",
        "\n",
        "        # Generator training (Encoder)\n",
        "        with tf.GradientTape() as gen_tape:\n",
        "            encoder_output = self.encode(batch_x, training=True)\n",
        "            dc_fake = self.discriminator(encoder_output, training=False)\n",
        "            gen_loss = self.binCe_loss_fn(tf.ones_like(dc_fake),dc_fake)\n",
        "\n",
        "        # Apply the gradients\n",
        "        gen_grads = gen_tape.gradient(gen_loss, self.encoder.trainable_variables)\n",
        "        self.gen_optimizer.apply_gradients(zip(gen_grads, self.encoder.trainable_variables))\n",
        "\n",
        "        # Update the metrics\n",
        "        self.ae_metrics.update_state(batch_x, X_reconstructed)\n",
        "        self.dc_metrics.update_state(tf.concat([tf.zeros_like(dc_fake), tf.ones_like(dc_real)], axis=0), tf.concat([dc_fake, dc_real], axis=0))\n",
        "        self.gen_metrics.update_state(tf.ones_like(dc_fake), dc_fake)\n",
        "        self.dc_acc_fn.update_state(tf.concat([tf.zeros_like(dc_fake), tf.ones_like(dc_real)], axis=0), tf.concat([dc_fake, dc_real], axis=0))\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZRG-lGv6t3Hu"
      },
      "outputs": [
        {
          "ename": "ResourceExhaustedError",
          "evalue": "failed to allocate memory [Op:Mul]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14160\\1744313876.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0maae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha_leaky\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0maae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_lr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_lr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_lr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgen_coef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14160\\2161912724.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, latent_dim, leaky_alpha, filters, kernel_size, strides, dense_units, discriminator_units, base_lr, max_lr, step_size, gen_coef, batch_size)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# Encoder Net\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleaky_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14160\\1300372113.py\u001b[0m in \u001b[0;36mget_encoder\u001b[1;34m(input_shape, latent_dim, leaky_alpha, filters, kernel_size, strides, dense_units)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mflatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdense_units\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mz_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    977\u001b[0m                                                 input_list)\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1112\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1113\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1115\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    846\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    884\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 886\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2657\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint:disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m       \u001b[1;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m       \u001b[1;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                        'should be defined. Found `None`.')\n\u001b[0;32m   1177\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m     self.kernel = self.add_weight(\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;34m'kernel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlast_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[0mcaching_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m     variable = self._add_variable_with_custom_getter(\n\u001b[0m\u001b[0;32m    648\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[1;31m# \"best effort\" to set the initializer with the highest restore UID.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheckpoint_initializer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 813\u001b[1;33m     new_variable = getter(\n\u001b[0m\u001b[0;32m    814\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    115\u001b[0m   \u001b[1;31m# However, this breaks legacy (Estimator) checkpoints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m   \u001b[1;31m# because it changes variable names. Remove this when V1 is fully deprecated.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m   return tf.compat.v1.Variable(\n\u001b[0m\u001b[0;32m    118\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m     return previous_getter(\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m                         shape=None):\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2610\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2611\u001b[0m     \u001b[0mdistribute_strategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"distribute_strategy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2612\u001b[1;33m     return resource_variable_ops.ResourceVariable(\n\u001b[0m\u001b[0;32m   2613\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2614\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1600\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_proto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1602\u001b[1;33m       self._init_from_args(\n\u001b[0m\u001b[0;32m   1603\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1738\u001b[0m           \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initializer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m               \u001b[0minitial_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\keras\\initializers\\initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\keras\\initializers\\initializers_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m    970\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m       \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m     return op(\n\u001b[0m\u001b[0;32m    973\u001b[0m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    313\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m     \u001b[1;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1708\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1709\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1710\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    528\u001b[0m   \"\"\"\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6233\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6234\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6235\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6236\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6237\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\source\\envs\\MLgeneric\\MLgeneric\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: failed to allocate memory [Op:Mul]"
          ]
        }
      ],
      "source": [
        "base_lr = 0.0001\n",
        "max_lr = 0.0025\n",
        "step_size = 2 * np.ceil(train_images.shape[0] / batch_size)\n",
        "epochs = 350\n",
        "\n",
        "latent_dim = 192\n",
        "alpha_leaky = 0.2\n",
        "filters = [64,128,256,512]\n",
        "kernel_size = [4,4,3,3]\n",
        "strides = [2,2,2,2]\n",
        "dense_units = [1000,300]\n",
        "discriminator_units = [200, 200]\n",
        "keep_prob = 0.5\n",
        "gen_coef = 2.\n",
        "\n",
        "steps_per_epoch = train_images.shape[0] / batch_size\n",
        "\n",
        "aae = AAE((length, width, channels), latent_dim, alpha_leaky, filters, kernel_size, strides, dense_units, discriminator_units, base_lr, max_lr, step_size, gen_coef, batch_size)\n",
        "aae.compile(tf.keras.optimizers.Adam(learning_rate = base_lr), tf.keras.optimizers.Adam(learning_rate=base_lr), tf.keras.optimizers.Adam(learning_rate=base_lr*gen_coef))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard('logs', histogram_freq=1)\n",
        "customAAECallback = CustomAAECallbacks(X=test_images[:10], schedule=lr_schedule, patience=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_3l2Plit3Hw",
        "outputId": "573547e8-35f9-42d3-adee-9dc425015294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "391/391 [==============================] - 80s 173ms/step - dc_accuracy: 0.3896 - ae_metrics: 0.0283 - dc_metrics: 4.0043 - gen_metrics: 1.2060 - val_dc_accuracy: 0.4881 - val_ae_metrics: 0.0583 - val_dc_metrics: 1.0180 - val_gen_metrics: 1.5787\n",
            "Epoch 2/350\n",
            "391/391 [==============================] - 68s 173ms/step - dc_accuracy: 0.4952 - ae_metrics: 0.0158 - dc_metrics: 0.8072 - gen_metrics: 1.2526 - val_dc_accuracy: 0.4907 - val_ae_metrics: 0.0458 - val_dc_metrics: 0.7314 - val_gen_metrics: 1.0333\n",
            "Epoch 3/350\n",
            "391/391 [==============================] - 67s 172ms/step - dc_accuracy: 0.4980 - ae_metrics: 0.0125 - dc_metrics: 0.7250 - gen_metrics: 0.9536 - val_dc_accuracy: 0.4965 - val_ae_metrics: 0.0240 - val_dc_metrics: 0.7425 - val_gen_metrics: 0.8775\n",
            "Epoch 4/350\n",
            "391/391 [==============================] - 67s 172ms/step - dc_accuracy: 0.4927 - ae_metrics: 0.0104 - dc_metrics: 0.7475 - gen_metrics: 0.7485 - val_dc_accuracy: 0.4897 - val_ae_metrics: 0.0118 - val_dc_metrics: 0.7584 - val_gen_metrics: 0.7000\n",
            "Epoch 5/350\n",
            "391/391 [==============================] - 67s 172ms/step - dc_accuracy: 0.4505 - ae_metrics: 0.0092 - dc_metrics: 0.8038 - gen_metrics: 0.5867 - val_dc_accuracy: 0.4774 - val_ae_metrics: 0.0094 - val_dc_metrics: 0.7666 - val_gen_metrics: 0.6200\n",
            "Epoch 6/350\n",
            "391/391 [==============================] - 67s 170ms/step - dc_accuracy: 0.4290 - ae_metrics: 0.0085 - dc_metrics: 0.8257 - gen_metrics: 0.5521 - val_dc_accuracy: 0.5145 - val_ae_metrics: 0.0087 - val_dc_metrics: 0.7471 - val_gen_metrics: 0.6446\n",
            "Epoch 7/350\n",
            "391/391 [==============================] - 66s 170ms/step - dc_accuracy: 0.3941 - ae_metrics: 0.0080 - dc_metrics: 0.8603 - gen_metrics: 0.4986 - val_dc_accuracy: 0.4943 - val_ae_metrics: 0.0089 - val_dc_metrics: 0.7551 - val_gen_metrics: 0.6473\n",
            "Epoch 8/350\n",
            "391/391 [==============================] - 67s 172ms/step - dc_accuracy: 0.3780 - ae_metrics: 0.0076 - dc_metrics: 0.8975 - gen_metrics: 0.4652 - val_dc_accuracy: 0.5156 - val_ae_metrics: 0.0115 - val_dc_metrics: 0.6953 - val_gen_metrics: 0.7847\n",
            "Epoch 9/350\n",
            "391/391 [==============================] - 67s 170ms/step - dc_accuracy: 0.3708 - ae_metrics: 0.0073 - dc_metrics: 0.9060 - gen_metrics: 0.4515 - val_dc_accuracy: 0.5640 - val_ae_metrics: 0.0089 - val_dc_metrics: 0.6916 - val_gen_metrics: 0.7587\n",
            "Epoch 10/350\n",
            "391/391 [==============================] - 67s 170ms/step - dc_accuracy: 0.3861 - ae_metrics: 0.0071 - dc_metrics: 0.9628 - gen_metrics: 0.4038 - val_dc_accuracy: 0.5551 - val_ae_metrics: 0.0087 - val_dc_metrics: 0.7088 - val_gen_metrics: 0.7342\n",
            "Epoch 11/350\n",
            "391/391 [==============================] - 68s 173ms/step - dc_accuracy: 0.3781 - ae_metrics: 0.0069 - dc_metrics: 0.9603 - gen_metrics: 0.4202 - val_dc_accuracy: 0.5250 - val_ae_metrics: 0.0076 - val_dc_metrics: 0.7023 - val_gen_metrics: 0.7158\n",
            "Epoch 12/350\n",
            "391/391 [==============================] - 67s 171ms/step - dc_accuracy: 0.3240 - ae_metrics: 0.0065 - dc_metrics: 0.9297 - gen_metrics: 0.3952 - val_dc_accuracy: 0.4553 - val_ae_metrics: 0.0066 - val_dc_metrics: 0.8143 - val_gen_metrics: 0.5550\n",
            "Epoch 13/350\n",
            "341/391 [=========================>....] - ETA: 8s - dc_accuracy: 0.3441 - ae_metrics: 0.0063 - dc_metrics: 0.9475 - gen_metrics: 0.3570"
          ]
        }
      ],
      "source": [
        "history = aae.fit(x=train_dataset, epochs=epochs, validation_data=test_dataset, callbacks=[tensorboard_callback, customAAECallback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aae.encoder.save('/content/drive/MyDrive/Blackboxes/enc_model')\n",
        "aae.decoder.save('/content/drive/MyDrive/Blackboxes/dec_model')\n",
        "aae.discriminator.save('/content/drive/MyDrive/Blackboxes/dc_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aae.encoder.save('enc_model')\n",
        "aae.decoder.save('dec_model')\n",
        "aae.discriminator.save('dc_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image = train_images[0,:,:,:].reshape((1,32,32,3))\n",
        "z = aae.encode(image)\n",
        "image_recon = aae.decode(z, apply_sigmoid=True)\n",
        "plt.figure()\n",
        "plt.imshow(image[0,:,:,:])\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.imshow(image_recon[0,:,:,:])\n",
        "plt.show()\n",
        "\n",
        "image = test_images[10,:,:,:].reshape((1,32,32,3))\n",
        "z = aae.encode(image)\n",
        "image_recon = aae.decode(z, apply_sigmoid=True)\n",
        "plt.figure()\n",
        "plt.imshow(image[0,:,:,:])\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.imshow(image_recon[0,:,:,:])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dc_accuracy, test_ae_loss, test_dc_loss, test_gen_loss = aae.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "z = np.random.randn(1,latent_dim)\n",
        "image = aae.decode(z, apply_sigmoid=True).numpy()\n",
        "image = image * 255.\n",
        "image=image.astype('int16')\n",
        "image.reshape((32,32,3))\n",
        "plt.figure()\n",
        "plt.imshow(image[0,:,:,:])\n",
        "plt.show()\n",
        "print(aae.discriminator(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_latent(aae, data, labels):\n",
        "    latent_data = aae.encode(data)\n",
        "    plt.scatter(latent_data[:,0], latent_data[:,1], c=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_latent(aae, train_images[0:1000], train_labels[0:1000].reshape((1000)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AAE_model.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "39ffb1c44105ac059136d352d026159bcca195c13c9355765ec3c2c6a6f716ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
